<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Oscar Nights by coppola-shi</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Oscar Nights</h1>
        <p>A predictive model for Academy Award performance by Antonio Coppola and Andy Shi, Harvard University.</p>

        <p class="view"><a href="https://github.com/coppola-shi/OscarNights">View the Project on GitHub <small>coppola-shi/OscarNights</small></a></p>


        <ul>
          <li><a href="https://github.com/coppola-shi/OscarNights/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/coppola-shi/OscarNights/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/coppola-shi/OscarNights">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h3>
<a id="welcome-to-oscar-nights" class="anchor" href="#welcome-to-oscar-nights" aria-hidden="true"><span class="octicon octicon-link"></span></a>Welcome to Oscar Nights</h3>

<p>Oscar Nights is a project realized for Harvard's Computer Science 109: Data Science. We aim to discover which movie features (budget, director, review statistics, etcâ€¦) are predictive of success on the night of the Academy Awards, and to see how well a classifier can predict Oscar nominations and Oscar winnings. The project comes in the form of an iPython notebook, with associated data files. In order to execute the code, extract the contents of the project archive locally, and then launch iPython.</p>

<iframe width="560" height="315" src="//www.youtube.com/embed/o6YXdTeuDCA" frameborder="0" allowfullscreen></iframe>

<p>   </p>

<h3>
<a id="project-specifications" class="anchor" href="#project-specifications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Project Specifications</h3>

<p>We build two classifiers: one allows us to predict whether a movie will be <em>nominated for at least one Oscar</em>, and the other allows us to predict whether an Oscar nominee <em>will win at least one Oscar</em>. Aside from building the predictive model, we are also interested in observing which features happen to be the most important predictors in the model.</p>

<p>We train the classifiers on data for over 1000 movies released between 2005 and 2009 from Noah Smith's <a href="http://www.ark.cs.cmu.edu/movie%24-data/">Movies Data Corpus</a>. This data includes movie reviews from sources such as the <a href="http://www.nytimes.com/pages/movies/index.html">New York Times</a> and the <a href="http://www.austinchronicle.com/screens/">Austin Chronicle</a>. In order to quantify the positiveness of the movie reviews (this task is commonly referred to as <em>sentiment analysis</em>), we also use <a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/">training data</a> from Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.</p>

<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h3>

<p>We are successfully able to predict Oscar nominations with an accuracy of <strong>95%</strong>, and to predict Oscar winnings with an accuracy of <strong>90%</strong>. Because the proportion of Oscar-winning and Oscar-nominated movies is very low, we also look at the F1 prediction score, a metric bounded between 0 (worst) and 1 (best) that gives an indication of both the true positive rate and the false positive rate. We perform very well still, achieving an F1 score of 0.87 for identifying Oscar nominees, and an F1 score of 0.89 for identifying Oscar winners.</p>

<p>We find that the strongest predictors of Academy award performance (both in terms of nominations and award winnings) are the qualities of the movie reviews, box office performance, production budget, running time, number of screens for the movie premiere, and day of the year in which the movie is released. The following graph shows feature importance for nominee prediction:</p>

<p><img src="https://dl.dropboxusercontent.com/u/113867121/features_nominee.png" alt=""></p>

<p>The following graph shows instead feature importance for winner prediction:</p>

<p><img src="https://dl.dropboxusercontent.com/u/113867121/features_winner.png" alt=""></p>

<p>As one might expect, we find that Oscar winners and Oscar nominees tend to receive better-than-average reviews.</p>

<p><img src="https://dl.dropboxusercontent.com/u/113867121/reviews.png" alt=""></p>

<p>Perhaps more surprisingly, however, we also find that movies that are released later in the year tend to perform better at the Academy Awards. This effect might be driven by big-budget holiday releases.</p>

<p><img src="https://dl.dropboxusercontent.com/u/113867121/days.png" alt=""></p>

<h3>
<a id="contact-us" class="anchor" href="#contact-us" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contact Us</h3>

<p>Have questions about the project? Open an issue on our Github repository and we will be happy to help!</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/coppola-shi">coppola-shi</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>